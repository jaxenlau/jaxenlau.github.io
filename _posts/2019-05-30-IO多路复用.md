---
layout: post
title: " [转]IO 多路复用"
date: 2019-05-30 15:40:56 +0800
categories: Linux
tags: [select, poll, epoll]
typora-root-url: ../../jaxenlau.github.io
typora-copy-images-to: ../images
---

IO 多路复用是指内核一旦发现进程指定的一个或者多个 IO 条件准备读取，它就通知该进程。IO 多路复用适用如下场合：

> 1. 当客户处理多个描述符时（一般是交互式输入和网络套接口），必须使用 I/O 复用。
> 2. 当一个客户同时处理多个套接口时，而这种情况是可能的，但很少出现。
> 3. 如果一个 TCP 服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到 I/O 复用。
> 4. 如果一个服务器即要处理 TCP，又要处理 UDP，一般要使用 I/O 复用。
> 5. 如果一个服务器要处理多个服务或多个协议，一般要使用 I/O 复用。

与多进程和多线程技术相比，`I/O 多路复用技术的最大优势是系统开销小，系统不必创建进程/线程`，也不必维护这些进程/线程，从而大大减小了系统的开销。

目前支持 I/O 多路复用的系统调用有 `select，pselect，poll，epoll`，I/O 多路复用就是`通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作`。`但 select，pselect，poll，epoll 本质上都是同步 I/O`，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步 I/O 则无需自己负责进行读写，异步 I/O 的实现会负责把数据从内核拷贝到用户空间。

对于 IO 多路复用机制不理解的同学，可以先行参考[《聊聊Linux 五种IO模型》](https://www.jianshu.com/p/486b0965c296)，来了解Linux五种 IO 模型。

# 1 select、poll、epoll 简介

epoll 跟 select 都能提供多路 I/O 复用的解决方案。在现在的 Linux 内核里有都能够支持，`其中 epoll 是 Linux 所特有，而 select 则应该是 POSIX 所规定`，一般操作系统均有实现。

## 1.1 select

**基本原理：**

> select 函数监视的文件描述符分 3 类，分别是 writefds、readfds、和 exceptfds。调用后 select 函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有 except），或者超时（timeout 指定等待时间，如果立即返回设为 NULL 即可），函数返回。当 select 函数返回后，可以通过遍历 fdset，来找到就绪的描述符。

**基本流程，如图所示：**

![IO多路复用-1](/images/IO多路复用-1.png)

select 目前几乎在所有的平台上支持，`其良好跨平台支持也是它的一个优点`。`select 的一个缺点在于单个进程能够监视的文件描述符的数量存在最大限制`，在 Linux 上一般为 1024，`可以通过修改宏定义甚至重新编译内核的方式提升这一限制`，但是这样也会造成效率的降低。

`select 本质上是通过设置或者检查存放 fd 标志位的数据结构来进行下一步处理`。这样所带来的缺点是：

> 1. **select 最大的缺陷就是单个进程所打开的 FD 是有一定限制的，它由 FD_SETSIZE 设置，默认值是 1024。**
> 一般来说这个数目和系统内存关系很大，`具体数目可以 cat /proc/sys/fs/file-max 察看`。32 位机默认是 1024 个。64 位机默认是 2048.
> 2. **对 socket 进行扫描时是线性扫描，即采用轮询的方法，效率较低。**
> 当套接字比较多的时候，每次 select 都要通过遍历 FD_SETSIZE 个 socket 来完成调度，不管哪个 socket 是活跃的，都遍历一遍。这会浪费很多 CPU 时间。`如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询`，这正是 epoll 与 kqueue 做的。
> 3. **需要维护一个用来存放大量 fd 的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大。**

## 1.2 poll

**基本原理：**

> `poll 本质上和 select 没有区别，它将用户传入的数组拷贝到内核空间`，然后查询每个 fd 对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有 fd 后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历 fd。这个过程经历了多次无谓的遍历。

**它没有最大连接数的限制，原因是它是基于链表来存储的，但是同样有一个缺点：**

> 1. `大量的 fd 的数组被整体复制于用户态和内核地址空间之间`，而不管这样的复制是不是有意义。
> 2. `poll 还有一个特点是“水平触发”`，如果报告了 fd 后，没有被处理，那么下次poll 时会再次报告该 fd。

**注意：**

> 从上面看，select 和 poll 都需要在返回后，`通过遍历文件描述符来获取已经就绪的 socket`。事实上，`同时连接的大量客户端在一时刻可能只有很少的处于就绪状态`，因此随着监视的描述符数量的增长，其效率也会线性下降。

## 1.3 epoll

epoll 是在 2.6 内核中提出的，是之前的 select 和 poll 的增强版本。相对于 select 和 poll 来说，epoll 更加灵活，没有描述符限制。`epoll 使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的 copy 只需一次`。

**基本原理：**

> `epoll 支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就绪态，并且只会通知一次`。还有一个特点是，`epoll 使用“事件”的就绪通知方式`，通过 epoll_ctl 注册 fd，`一旦该 fd 就绪，内核就会采用类似 callback 的回调机制来激活该 fd`，epoll_wait 便可以收到通知。

**epoll的优点：**

> 1. `没有最大并发连接的限制`，能打开的 fd 的上限远大于 1024（1G 的内存上能监听约 10 万个端口）。
> 2. `效率提升，不是轮询的方式，不会随着 fd 数目的增加效率下降`。只有活跃可用的 fd 才会调用 callback 函数；`即 epoll 最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关`，因此在实际的网络环境中，epoll 的效率就会远远高于 select 和 poll。
> 3. `内存拷贝`，利用 mmap() 文件映射内存加速与内核空间的消息传递；`即 epoll 使用 mmap 减少复制开销`。

**epoll对文件描述符的操作有两种模式：LT（level trigger）和 ET（edge trigger）。 LT 模式是默认模式，LT 模式与 ET 模式的区别如下：**

> LT 模式：当 epoll_wait 检测到描述符事件发生并将此事件通知应用程序，`应用程序可以不立即处理该事件`。下次调用 epoll_wait 时，会再次响应应用程序并通知此事件。
>
> ET 模式：当 epoll_wait 检测到描述符事件发生并将此事件通知应用程序，`应用程序必须立即处理该事件`。如果不处理，下次调用 epoll_wait 时，不会再次响应应用程序并通知此事件。

1. **LT 模式**

> `LT(level triggered)是缺省的工作方式，并且同时支持 block 和 no-block socket`。在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的 fd 进行 IO 操作。`如果你不作任何操作，内核还是会继续通知你的`。

1. **ET 模式**

> `ET(edge-triggered)是高速工作方式，只支持 no-block socket`。在这种模式下，当描述符从未就绪变为就绪时，内核通过 epoll 告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个 EWOULDBLOCK 错误）。`但是请注意，如果一直不对这个 fd 作 IO 操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once)`。
>
> `ET 模式在很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高`。epoll 工作在 ET 模式的时候，`必须使用非阻塞套接口`，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。

1. 在 select/poll 中，`进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描`，而 epoll 事先通过 epoll_ctl() 来注册一个文件描述符，`一旦基于某个文件描述符就绪时，内核会采用类似 callback 的回调机制`，迅速激活这个文件描述符，当进程调用 epoll_wait() 时便得到通知。(`此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是 epoll 的魅力所在。`)

**注意：**

> 如果没有大量的 idle-connection 或者 dead-connection，epoll 的效率并不会比 select/poll 高很多，但是当遇到大量的 idle-connection，就会发现 epoll 的效率大大高于 select/poll。

# 2 select、poll、epoll 区别

## 2.1 支持一个进程所能打开的最大连接数

| I/O 多路复用 | 最大连接数限制                                               |
| ------------ | ------------------------------------------------------------ |
| select       | 单个进程所能打开的最大连接数有 FD_SETSIZE 宏定义，其大小是 32 个整数的大小（在 32 位机器上，大小就是 32 * 32，同理 64 位机器上 FD_SETSIZE 位 32 * 64），当然我们也可以对这个宏进行修改，然后重新编译内核，但是性能可能会受到影响，这需要进一步测试 |
| poll         | poll 本质上和 select 没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的 |
| epoll        | epoll 虽然连接数没有上限，但是很大，1G 内存的机器上可以打开 10 万左右的连接，2G 内存的机器上可以打开 20 万左右的连接 |

## 2.2 FD 剧增后带来的 IO 效率问题

| I/O 多路复用 | IO 效率问题                                                  |
| ------------ | ------------------------------------------------------------ |
| select       | 由于每次调用时都会对连接进行线性遍历，因此随着 FD 的增加会造成遍历的速度慢导致的 “线性下降性能问题” |
| poll         | 同上 ⬆                                                       |
| epoll        | 因为 epoll 在内核中的实现是根据每个 FD 上的 callback 函数来实现的，只有活跃的 socket 才会主动调用 callback 函数，所以在活跃 socket 较少的情况下，使用 epoll 没有前面两者的线形下降的性能问题，但是所有的 socket 都很活跃的情况下，可能会有性能问题。 |

## 2.3 消息传递方式

| I/O 多路复用 | 消息传递                                       |
| ------------ | ---------------------------------------------- |
| select       | 内核需要将消息传递到用户空间，需要内核拷贝操作 |
| poll         | 同上 ⬆                                         |
| epoll        | epoll 通过内核和用户空间共享一块内存来实现     |

## 2.4 总结

**综上，在选择 select，poll，epoll 时要根据具体的使用场合以及这三种方式的自身特点：**

> 1. 表面上看 epoll 的性能最好，`但是在连接数少并且连接都十分活跃的情况下，select 和 poll 的性能可能比 epoll 好`，毕竟 epoll 的通知机制需要很多函数回调。
> 2. `select 低效是因为每次它都需要轮询`。但低效也是相对的，视情况而定，也可通过良好的设计改善。



原文链接: <https://www.jianshu.com/p/dfd940e7fca2>